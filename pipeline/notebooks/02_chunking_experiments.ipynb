{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 â€“ Chunking Experiments\n",
        "\n",
        "This notebook is for trying different chunking strategies.\n",
        "\n",
        "- Import `FixedWindowChunker`, `MarkdownHeadingChunker`, and `PageMarkerChunker`.\n",
        "- Compare chunk length distributions and metadata.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src directory to path so we can import modules\n",
        "sys.path.insert(0, str(Path(\"../src\").resolve()))\n",
        "\n",
        "from loaders import get_loader_for_path\n",
        "from cleaning import clean_text\n",
        "from chunking.fixed_window import FixedWindowChunker\n",
        "\n",
        "DATA_DIR = Path(\"../data/raw\")\n",
        "\n",
        "files = sorted(DATA_DIR.rglob(\"*\"))\n",
        "\n",
        "supported_suffixes = {\".txt\", \".md\", \".pdf\", \".json\", \".csv\"}\n",
        "\n",
        "candidates = [\n",
        "    f for f in files\n",
        "    if f.is_file() and f.suffix.lower() in supported_suffixes\n",
        "]\n",
        "\n",
        "if not candidates:\n",
        "    raise RuntimeError(\"No supported files found.\")\n",
        "\n",
        "sample_path = candidates[0]\n",
        "print(f\"Using sample file: {sample_path}\")\n",
        "\n",
        "loader = get_loader_for_path(sample_path)\n",
        "doc = loader.load(sample_path)[0]\n",
        "\n",
        "doc.text = clean_text(doc.text)\n",
        "print(f\"Loaded Document: {doc.id}\")\n",
        "print(f\"Length of cleaned text: {len(doc.text)} chars\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try different fixed-window configs\n",
        "configs = [\n",
        "    {\"size\": 300, \"overlap\": 50},\n",
        "    {\"size\": 600, \"overlap\": 100},\n",
        "    {\"size\": 1000, \"overlap\": 200},\n",
        "]\n",
        "\n",
        "for cfg in configs:\n",
        "    chunker = FixedWindowChunker(size=cfg[\"size\"], overlap=cfg[\"overlap\"])\n",
        "    chunks = chunker.chunk(doc)\n",
        "    lengths = [len(c.text) for c in chunks]\n",
        "\n",
        "    print(\"\\n====================================================\")\n",
        "    print(f\"Chunk config: size={cfg['size']} overlap={cfg['overlap']}\")\n",
        "    print(f\"Number of chunks: {len(chunks)}\")\n",
        "    print(\n",
        "        f\"Min length: {min(lengths)}  Max length: {max(lengths)}  \"\n",
        "        f\"Avg: {sum(lengths)/len(lengths):.1f}\"\n",
        "    )\n",
        "    print(\"First chunk preview:\")\n",
        "    print(chunks[0].text[:300])\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
